#!/bin/bash

#SBATCH --job-name=run_train
#SBATCH --partition=gpu
#SBATCH --nodes=1
#SBATCH --gpus-per-node=2
#SBATCH --output=run_train_12_5.out
#SBATCH --time=1:00:00

source /sw/languages/anaconda/anaconda.3.9.13-2022-torch-cuda-11.7.0/etc/profile.d/conda.sh
conda activate sparse-tokens
torchrun --nproc-per-node=2 train.py --model sparse_token_vit_b_16 --epochs 10 --batch-size 64 --opt adamw --lr 0.003 --wd 0.3 --amp --device cuda --output-dir ""